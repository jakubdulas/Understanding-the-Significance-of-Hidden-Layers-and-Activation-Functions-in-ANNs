{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        image = self.df.iloc[idx, 1:]\n",
    "        sample = {'image': np.array(image), 'label': np.array(self.df.iloc[idx, 0])}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "    \n",
    "class Rescale(object):\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "        return {'image': image/255, 'label': label}\n",
    "\n",
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "        return {'image': torch.from_numpy(image).type(torch.float),\n",
    "                'label': torch.from_numpy(label).type(torch.long)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNISTDataset(csv_file='fashion-mnist_train.csv',\n",
    "                                           transform=transforms.Compose([\n",
    "                                               Rescale(),\n",
    "                                               ToTensor()\n",
    "                                           ]))\n",
    "\n",
    "test_dataset = MNISTDataset(csv_file='fashion-mnist_test.csv',\n",
    "                                           transform=transforms.Compose([\n",
    "                                               Rescale(),\n",
    "                                               ToTensor()\n",
    "                                           ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16,\n",
    "                        shuffle=True, num_workers=0)\n",
    "\n",
    "test_dataloader = DataLoader(train_dataset, batch_size=16,\n",
    "                        shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def save_to_csv(model_name, epoch, train_acc, train_loss, test_acc, test_loss):\n",
    "    filename = model_name+'.csv'\n",
    "    data = {'epoch':[epoch], \n",
    "            'train_acc':[train_acc], \n",
    "            'train_loss':[train_loss],\n",
    "            'test_acc':[test_acc],\n",
    "            'test_loss':[test_loss],\n",
    "    } \n",
    "    if not os.path.exists(model_name+'.csv'):\n",
    "        df = pd.DataFrame(data) \n",
    "        df.to_csv(filename, index=False)\n",
    "    else:\n",
    "        df = pd.read_csv(filename)\n",
    "        data = {k: v[0] for k, v in data.items()}\n",
    "        # df = df.append(data, ignore_index = True) \n",
    "        df.loc[len(df.index)] = [epoch, train_acc, train_loss, test_acc, test_loss]  \n",
    "        df.to_csv(filename, index=False)\n",
    "\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100 \n",
    "    return acc\n",
    "\n",
    "def train(model, model_name, train_dataloader, test_dataloader, loss_fn, epochs = 100, lr=0.01):\n",
    "    optimizer = torch.optim.SGD(params=model.parameters(), \n",
    "                            lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_acc = 0\n",
    "        train_loss = 0\n",
    "        test_acc = 0\n",
    "        test_loss = 0\n",
    "        \n",
    "        for sample in train_dataloader:\n",
    "            X = sample['image']\n",
    "            y = sample['label']\n",
    "            model.train()\n",
    "\n",
    "            y_logits = model(X).squeeze() \n",
    "            loss = loss_fn(y_logits, y)\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            y_pred = y_logits.argmax(dim=1)\n",
    "            acc = accuracy_fn(y, y_pred)\n",
    "            train_acc += acc\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_acc /= len(train_dataloader)\n",
    "        train_loss /= len(train_dataloader)\n",
    "        test_acc, test_loss = test(model, test_dataloader, loss_fn)\n",
    "\n",
    "        save_to_csv(model_name, epoch, train_acc, train_loss, test_acc, test_loss)\n",
    "\n",
    "        if epoch+1 % 10 == 0:\n",
    "            print(\"Epoch:\", epoch, \"; Acc:\", train_acc, \"; Loss:\", train_loss, \"; test acc:\", test_acc, \"; test loss:\", test_loss)\n",
    "        \n",
    "    return model\n",
    "\n",
    "def test(model, dataloader, loss_fn):\n",
    "    model.eval()\n",
    "    test_acc = 0\n",
    "    test_loss = 0\n",
    "    with torch.inference_mode():\n",
    "        for sample in dataloader:\n",
    "            X = sample['image']\n",
    "            y = sample['label']\n",
    "\n",
    "            y_logits = model(X).squeeze()\n",
    "            loss = loss_fn(y_logits, y)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            acc = accuracy_fn(y, y_logits.argmax(dim=1))\n",
    "            test_acc += acc\n",
    "            \n",
    "    return test_acc/len(dataloader), test_loss/len(dataloader)\n",
    "\n",
    "def plot_training_data(model_name, title=None, save=False):\n",
    "    df = pd.read_csv(model_name+'.csv')\n",
    "    fig, axs = plt.subplots(2, 2)\n",
    "    if title is None:\n",
    "        fig.suptitle(model_name+' results')\n",
    "    else:\n",
    "        fig.suptitle(title)\n",
    "    axs[0, 0].set_title('Train loss')\n",
    "    axs[0, 0].plot(df['epoch'].to_list(), df['train_loss'].to_list())\n",
    "    axs[0, 1].set_title('Train acc')\n",
    "    axs[0, 1].plot(df['epoch'].to_list(), df['train_acc'].to_list())\n",
    "    axs[1, 0].set_title('Test loss')\n",
    "    axs[1, 0].plot(df['epoch'].to_list(), df['test_loss'].to_list())\n",
    "    axs[1, 1].set_title('Test acc')\n",
    "    axs[1, 1].plot(df['epoch'].to_list(), df['test_acc'].to_list())\n",
    "    fig.show()\n",
    "    if save:\n",
    "        fig.savefig(model_name+'_metrics'+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "lr = 0.1\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "results = {}\n",
    "\n",
    "for num_layers in range(1, 4):\n",
    "    for num_neurons in [8, 16, 32, 64, 128]:\n",
    "        if num_layers == 0 and num_neurons != 8:\n",
    "            continue\n",
    "        if num_layers == 0:\n",
    "            model = nn.Sequential(\n",
    "                nn.Linear(784, 10),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "            name = 'model0'\n",
    "        else:\n",
    "            model = nn.Sequential(\n",
    "                nn.Linear(784, num_neurons),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "\n",
    "            for i in range(num_layers-1):\n",
    "                model.add_module(f'linear_layer{i}', nn.Linear(num_neurons, num_neurons))\n",
    "                model.add_module(f'relu_layer{i}', nn.ReLU())\n",
    "\n",
    "            model.add_module('output', nn.Linear(num_neurons, 10))\n",
    "            name = f'model{num_layers}_{num_neurons}'\n",
    "\n",
    "        model = train(model, name, train_dataloader, test_dataloader, loss_fn, epochs=num_epochs, lr=lr)\n",
    "        loss, acc = test(model, test_dataloader, nn.CrossEntropyLoss())\n",
    "        results[name] = {\n",
    "            'test loss': loss,\n",
    "            'test acc': acc\n",
    "        }\n",
    "        plot_training_data(name, save=True)\n",
    "\n",
    "\n",
    "def stringify_results(results):\n",
    "    s = \"\"\n",
    "    for model_name, params in results.items():\n",
    "        s += model_name + \"\\n\"\n",
    "        for k, v in params.items():\n",
    "            if k != 'model':\n",
    "                s += f'\\t{k}: {v}\\n'\n",
    "    return s\n",
    "\n",
    "str_results = stringify_results(results)\n",
    "\n",
    "with open(\"experiment2.txt\", 'w+') as f:\n",
    "    f.write(str_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
